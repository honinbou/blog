<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<title>honinbou</title>
	<link href="http://iguowei.net/atom.xml" rel="self" />
	<link href="http://iguowei.net/" />
	<updated>2012-12-31T16:57:51+08:00</updated>
	<id>http://iguowei.net/</id>
	<author>
		<name>honinbou</name>
		<email>weiguo85@gmail.com</email>
	</author>
	
	<entry>
		<title>性能测试和调优</title>
		<link href="http://iguowei.net/posts/performance-test.html" />
		<updated>2012-11-24T00:00:00+08:00</updated>
		<id>http://iguowei.net/posts/performance-test.html</id>
		<content type="html"><![CDATA[<p>性能测试和调优是一个比较复杂的问题，涉及到很多方面，这里总结一下之前做性能测试，查找系统瓶颈的经验。业界已经有人写了很多关于性能优化方法的文章，如：coolshell的博主陈皓的<a href="http://coolshell.cn/articles/7490.html (性能调优攻略)">《性能调优攻略》</a></p>

<h1 id="section">系统性能的定义</h1>
<p>对系统性能的度量，是我们后续定位和优化的第一步，开展性能测试，一般都是先测试出单机单模块的性能，根据这个基础性能，对各个模块的配比有个基本的认识。在组合出最平衡的组合后，对其进行性能测试，线上也按照这个比例上线，基本可以确定整个集群的服务能力。</p>

<p>一般我们无法直接对整个集群的服务能力进行测试，比如线上1000台云存储服务的集群，可能没有条件对这1000台进行性能测试，因为你需要大量的client机器，当然这种计算可能会不太准，会有一定比例的折损，因为大的系统中可能涉及网络通讯，试错等逻辑，导致实际结果偏低。</p>

<p>系统性能的定义一般有三个指标：</p>

<ol>
  <li><strong>QPS</strong>(query per second) 每秒请求数，即服务器每秒能够服务的请求数目，单位：次/s；</li>
  <li><strong>Latency</strong> 时延，即每次请求所花费的时间，单位：ms；</li>
  <li><strong>Throughput</strong> 吞吐量 即网路卡上的数据流量，单位：KB/s, MB/s, etc；</li>
</ol>

<p>三者之间有一定的制约关系：</p>

<ol>
  <li>一般QPS越高，latency会越长，Throughput会越大，因为系统会更繁忙，可能会存在额外的调度等待导致latency变长，Throughput也会响应增加；</li>
  <li>Latency越低，代表请求很快就结束了，这样单位时间内能够容纳的请求就越多，QPS就可以越高；</li>
  <li>Throughput一般只要不是到达网卡瓶颈，基本上都不会有影响，但是需要注意，在目前多核心的机器上，如果网卡的中断能够均匀分布到多个核心上，能提高不少机器的性能；</li>
</ol>

<p>系统的这个三个指标随着压力的增大，而没有提升，均是系统的某种资源达到瓶颈。下面介绍如何查看系统的稀缺资源</p>

<h1 id="section-1">系统资源介绍</h1>
<p>对于计算机系统，一般的瓶颈在于三个方面：CPU、内存、IO，IO又分磁盘IO和网卡IO，下面分别对这四个资源的度量进行介绍</p>

<h2 id="cpu">CPU</h2>
<p>CPU在linux系统中主要完成三个任务：</p>

<ol>
  <li>用户态进程的执行</li>
  <li>系统内核的执行</li>
  <li>idle状态</li>
</ol>

<h3 id="cpu-1">cpu的度量</h3>

<p>CPU的上述三个状态进一步细分可以分为：</p>

<ul>
  <li>user CPU用于执行用户态进程的比例</li>
  <li>nice CPU用于切换用户态进程的nice值的比例</li>
  <li>sys CPU用于执行内核态的的比例，不包括软中断和硬中断的时间</li>
  <li>iowait CPU用于IO操作的比例</li>
  <li>irq CPU用户硬中断的比例</li>
  <li>soft CPU用于软中断的比例</li>
  <li>steal hypervisor服务另一个虚拟处理器的时候，虚拟CPU等待实际CPU的时间的百分比.<a href="http://rackerhacker.com/2008/11/04/what-is-steal-time-in-my-sysstat-output/">英文</a>.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></li>
  <li>guest CPU执行虚拟CPU作业的时间</li>
  <li>idle CPU闲置的时间比例</li>
</ul>

<p>满足关系：</p>

<pre><code>CPU总的工作时间 = total_cur = user + system + nice + idle + iowait + \
	irq + softirq

total_pre = pre_user + pre_system + pre_nice + pre_idle + \
	pre_iowait + pre_irq + pre_softirq

user = user_cur - user_pre

total = total_cur - total_pre

total = user + system + nice + idle + iowait + irq + softirq
</code></pre>

<h3 id="cpu-2">cpu时间的计算</h3>

<h4 id="tick">tick</h4>
<p>Linux核心每隔固定周期会发出timer interrupt (IRQ 0)，这个时间就是tick，它是核心度量时间的基本单位<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。
tick是HZ的倒数，HZ的值可在编译核心时设定，可设定100、250、300或1000，查看本机的HZ的值可以通过如下命令来查看：</p>

<pre><code>cat /boot/config-`uname -r` | grep "^CONFIG_HZ"
</code></pre>

<h4 id="cpu-3">CPU时间</h4>
<p>CPU的数据信息被记录在/proc/stat文件中，单位时tick，内核中有个变量，jiffies，来记录自系统启动以来经历的tick数量。内核在时钟中断程序中，即每个tick更新一次CPU信息。CPU的时间消耗，记录在/proc/stat文件中，CPU的时间消耗就是根据该文件的内容计算而来，文件内容大致如下:</p>

<pre><code>cpu  111262 29371 158809 4489873 24328 2420 1609 0 0
cpu0 53992 14114 68808 2228130 20065 1123 876 0 0
cpu1 57269 15256 90000 2261743 4263 1296 733 0 0
intr 7848496 4165587 4555 0 0 0 0 0 0 1 29100 0 0 184931 0 0 0 2878 739856 0 82597 0 0 0 19 0 0 0 65126 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ctxt 15480484
btime 1354326511
processes 4721
procs_running 1
procs_blocked 0
softirq 8334431 513266 2992461 1 27910 82629 0 3492 1637012 1203 3076457
</code></pre>

<p>CPU信息中，cpu代表CPU总的信息，cpu0,&#8230;,cpun为各个具体CPU的信息。</p>

<ul>
  <li>cpu信息分别代表的意义：user, nice, sys, idle, iowait time, Hard irq time, Soft irq time, steal time, guest time</li>
  <li>intr 这行给出中断的信息，第一个为自系统启动以来，发生的所有的中断的次数；然后每个数对应一个特定的中断自系统启动以来所发生的次数。 &lt;/font&gt;&lt;/p&gt;</li>
  <li>ctxt 给出了自系统启动以来CPU发生的上下文交换的次数</li>
  <li>btime 给出了从系统启动到现在为止的时间，单位为秒<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>.</li>
  <li>processes (total_forks) 自系统启动以来所创建的任务的个数目。</li>
  <li>procs_running 当前运行队列的任务的数目。</li>
  <li>procs_blocked 当前被阻塞的任务的数目。</li>
  <li>后一个softirq意义不明确</li>
</ul>

<p>CPU时间的计算，就是通过intval时间内tick数目的对比，得到CPU的统计信息</p>

<h3 id="cpu-4">进程在CPU中的状态</h3>
<p>我们进行性能测试，除了需要关注上面的CPU Utilization信息，也需要查看进程在操作系统中的状态，进程在CPU中的状态迁移如下图：</p>

<p><img src="/assets/pic/2012-11-24-cpu-proccess.jpg" alt="cpu-process" title="进程的状态迁移图" /></p>

<p>process有两种状态：</p>

<ol>
  <li>runnable</li>
  <li>blocked waiting for an event to complete</li>
</ol>

<p>一个blocked状态的process可能在等待一个I/O操作获取的数据，或者是一个系统调用的结果。</p>

<p>一个process在runnable状态，这就意味着它将同其他runnable状态的process等待CPU时间，而不是立即获得CPU时间，一个runnable状态的process不需要消耗CPU时间。所有process处在runnable状态且等待CPU时间时，形成的等待队列称作Run Queue。Run Queue越大，表示CPU的压力越大。</p>

<p>性能工具通常显示runnable processes的数目和blocked processes的数目。<br />
还有一个很常见的系统状态是load average，系统的load是指running和runnable process的总和。<br />
例如：如果有2个processes在running和有3个在等待运行(runnable)，那么系统的load为5。load average是指在指定时间内load的平均值。一般load average显示的三个数字的时间分别为1分钟，五分钟和十五分钟。一般loadavg的个数，不超过CPU核心的个数，代表CPU的资源不是瓶颈。</p>

<h3 id="cpu-5">cpu状态的查看和相关命令</h3>

<h4 id="vmstat">vmstat</h4>

<p>vmstat只能查看所有CPU的平均信息，包括CPU，内存，虚拟内存，IO，SYS和CPU等，同时也可以查看cpu队列信息；。</p>

<pre><code>guowei@guowei-laptop:~$ vmstat -n 1
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
3  0      0 559184 136856 1028320    0    0    25    34  221  489 17  7 76  1
0  0      0 560112 136856 1028680    0    0     0     0  686 2182 46 48  6  0
3  0      0 559324 136864 1029244    0    0     0    52  841 3286 42 43 15  0
2  0      0 558960 136864 1029708    0    0     0     0  891 2905 41 41 19  0
1  0      0 558228 136864 1030052    0    0     0     0  678 1778 46 43 10  0
1  0      0 556800 136864 1030632    0    0     0     0  664 1966 44 50  6  0
</code></pre>

<ol>
  <li>PROC(ESSES)
    <ul>
      <li>&#8211;r:如果在processes中运行的序列(process r)是连续的大于在系统中的CPU的个数,表示系统现在运行比较慢,有多数的进程等待CPU。如果r的输出数大于系统中可用CPU个数的4倍的话,则系统面临着CPU短缺的问题,或者是CPU的速率过低,系统中有多数的进程在等待CPU,造成系统中进程运行过慢.</li>
      <li>&#8211;b:在internal时间段里，被资源阻塞的任务数（I/0，页面调度，等等.），通常情况下是接近0的 procs_blocked</li>
    </ul>
  </li>
  <li>SYSTEM
    <ul>
      <li>&#8211;in:每秒产生的中断次数</li>
      <li>&#8211;cs:每秒产生的上下文切换次数
 上面2个值越大，会看到由内核消耗的CPU时间会越大</li>
    </ul>
  </li>
  <li>CPU
    <ul>
      <li>&#8211;us:用户进程消耗的CPU时间百分。us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速（比如PHP/PERL）</li>
      <li>&#8211;sy:内核进程消耗的CPU时间百分比。（sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因）</li>
      <li>&#8211;wa:IO等待消耗的CPU时间百分比。wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。</li>
      <li>&#8211;id:CPU处于空闲状态时间百分比。如果空闲时间(cpu id)持续为0并且系统时间(cpu sy)是用户时间的两倍(cpu us) 系统则面临着CPU资源的短缺.</li>
    </ul>
  </li>
  <li>解决办法</li>
</ol>

<ul>
  <li>分析程序的业务场景，看看使用的模型是否适合该种业务；</li>
  <li>使用多种诊断工具，具体定位程序消耗了更多的何种资源；</li>
  <li>prof代码，查看代码的瓶颈；</li>
  <li>考虑增加更多更好的CPU. 
更多的分析方法，参见<a href="http://coolshell.cn/articles/7490.html (性能调优攻略)">《性能调优攻略》</a></li>
</ul>

<h4 id="mpstat">mpstat：</h4>

<p>mpstat 是Multiprocessor Statistics的缩写，是实时系统监控工具。其报告与CPU相关的一些统计信息，这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。下面只介绍 mpstat与CPU相关的参数，mpstat的语法如下：</p>

<pre><code>guowei@guowei-laptop:~$ mpstat -P ALL 2 2
Linux 2.6.32-21-generic (guowei-laptop) 	12/01/2012 	_i686_	(2 CPU)

08:46:16 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle
08:46:18 PM  all   39.60    0.00   29.82    0.00    0.00   11.53    0.00    0.00   19.05
08:46:18 PM    0   33.33    0.00   28.86    0.00    0.00   11.44    0.00    0.00   26.37
08:46:18 PM    1   45.73    0.00   30.65    0.00    0.00   12.06    0.00    0.00   11.56

08:46:18 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle
08:46:20 PM  all   36.88    0.00   29.70    0.00    0.00    9.90    0.00    0.00   23.51
08:46:20 PM    0   35.50    0.00   29.00    0.00    0.00   11.00    0.00    0.00   24.50
08:46:20 PM    1   38.42    0.00   30.05    0.00    0.00    8.87    0.00    0.00   22.66

Average:     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle
Average:     all   38.23    0.00   29.76    0.00    0.00   10.71    0.00    0.00   21.30
Average:       0   34.41    0.00   28.93    0.00    0.00   11.22    0.00    0.00   25.44
Average:       1   42.04    0.00   30.35    0.00    0.00   10.45    0.00    0.00   17.16
</code></pre>

<p>参数的含义如下：</p>

<ul>
  <li>-P{|ALL} 表示监控哪个CPU，cpu在[0,cpu个数-1]中取值</li>
  <li>internal 相邻的两次采样的间隔时间</li>
  <li>count 采样的次数，count只能和delay一起使用</li>
</ul>

<p>当没有参数时，mpstat则显示系统启动以后所有信息的平均值。有interval时，第一行的信息自系统启动以来的平均信息。从第二行开始，输出为前一个interval时间段的平均信息。与CPU有关的输出的参数的意义如上在CPU的度量中的解释</p>

<h4 id="iostat">iostat:</h4>
<p>只能查看所有CPU的平均信息。</p>

<pre><code>guowei@guowei-laptop:~$ iostat -c 2 2
Linux 2.6.32-21-generic (guowei-laptop) 	12/01/2012 	_i686_	(2 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          26.79    0.22   22.35    0.42    0.00   50.21

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          42.89    0.00   47.88    0.00    0.00    9.23
</code></pre>

<p>注：这里的system包括了irq和softirq的时间	          </p>

<h4 id="sar">sar：</h4>
<p>与mpstat 一样，不但能查看CPU的平均信息，还能查看指定CPU的信息。<br />
sar [options] [-A] [-o file] t [n]</p>

<p>在命令行中，n 和t 两个参数组合起来定义采样间隔和次数，t为采样间隔，是必须有的参数，n为采样次数，是可选的，默认值是1，-o file表示将命令结果以二进制格式存放在文件中，file 在此处不是关键字，是文件名。options 为命令行选项，sar命令的选项很多，下面只列出常用选项：</p>

<pre><code>-A：所有报告的总和。
-u：CPU利用率
-v：进程、I节点、文件和锁表状态。
-d：硬盘使用报告。
-r：内存和交换空间的使用统计。
-g：串口I/O的情况。
-b：缓冲区使用情况。
-a：文件读写情况。
-c：系统调用情况。
-q：报告队列长度和系统平均负载
-R：进程的活动情况。
-y：终端设备活动情况。
-w：系统交换活动。
-x { pid | SELF | ALL }：报告指定进程ID的统计信息，SELF关键字是sar进程本身的统计，ALL关键字是所有系统进程的统计。
</code></pre>

<ul>
  <li>用sar进行CPU利用率的分析  </li>
</ul>

<p>例如:</p>

<pre><code>guowei@guowei-laptop:home$ sar -u 1 5
Linux 2.6.32-21-generic (guowei-laptop) 	12/01/2012 	_i686_	(2 CPU)

10:56:49 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle
10:56:50 PM     all     39.80      0.00     50.75      0.00      0.00      9.45
10:56:51 PM     all     43.22      0.00     46.23      0.50      0.00     10.05
10:56:52 PM     all     47.50      0.00     40.00      0.00      0.00     12.50
10:56:53 PM     all     40.30      0.00     46.77      0.00      0.00     12.94
10:56:54 PM     all     38.31      0.00     43.28      0.00      0.00     18.41
Average:        all     41.82      0.00     45.41      0.10      0.00     12.67
</code></pre>

<p>在显示内容包括：</p>

<ul>
  <li>%user：CPU处在用户模式下的时间百分比。</li>
  <li>%nice：CPU处在带NICE值的用户模式下的时间百分比；</li>
  <li>%system：CPU处在系统模式下的时间百分比，包括irq和softirq的值；</li>
  <li>%iowait：CPU等待输入输出完成时间的百分比。</li>
  <li>%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的等待时间百分比。</li>
  <li>%idle：CPU空闲时间百分比。</li>
</ul>

<p>在所有的显示中，我们应主要注意%iowait和%idle，%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。</p>

<ul>
  <li>用sar进行运行进程队列长度分析：</li>
</ul>

<p>例如：</p>

<pre><code>guowei@guowei-laptop:home$ sar -q 2 3
Linux 2.6.32-21-generic (guowei-laptop) 	12/01/2012 	_i686_	(2 CPU)
11:02:03 PM   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15
11:02:05 PM         1       280      2.51      2.28      2.24
11:02:07 PM         2       280      2.51      2.28      2.24
11:02:09 PM         3       280      2.63      2.31      2.25
Average:            2       280      2.55      2.29      2.24
</code></pre>

<p>其中:  </p>

<ul>
  <li>runq-sz 准备运行的进程运行队列。</li>
  <li>plist-sz  进程队列里的进程和线程的数量</li>
  <li>ldavg-1  前一分钟的系统平均负载(load average)</li>
  <li>ldavg-5  前五分钟的系统平均负载(load average)</li>
  <li>ldavg-15  前15分钟的系统平均负载(load average)</li>
</ul>

<p>load average可以理解为每秒钟CPU等待运行的进程个数. 在Linux系统中，sar -q、uptime、top等命令都会有系统平均负载load average的输出, 系统平均负载被定义为在特定时间间隔内运行队列中的平均任务数。如果一个进程满足以下条件则其就会位于运行队列中：  </p>

<ul>
  <li>它没有在等待I/O操作的结果</li>
  <li>它没有主动进入等待状态(也就是没有调用&#8217;wait&#8217;)</li>
  <li>没有被停止(例如：等待终止)</li>
</ul>

<h4 id="top">top：</h4>
<p>显示的信息同ps接近，但是top可以了解到CPU消耗，可以根据用户指定的时间来更新显示。</p>

<pre><code>Tasks: 172 total,   4 running, 166 sleeping,   1 stopped,   1 zombie
Cpu0  : 38.6%us, 34.3%sy,  0.0%ni, 14.4%id,  0.0%wa,  0.0%hi, 12.7%si,  0.0%st
Cpu1  : 40.3%us, 31.5%sy,  0.0%ni, 14.8%id,  0.0%wa,  0.0%hi, 13.4%si,  0.0%st
Mem:   2050816k total,  1995024k used,    55792k free,     8468k buffers
Swap:  2999992k total,      464k used,  2999528k free,  1690900k cached

PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND              
2635 guowei    20   0 13668  10m  964 R   74  0.5 131:26.01 curl-loader               
2417 guowei    20   0  5364 3704  620 R   47  0.2  79:23.80 lighttpd     
</code></pre>

<p>在显示内容包括：</p>

<ul>
  <li>Tasks：表示总共运行的task，running的个数，sleeping的个数，stop的个数，zobie的个数</li>
  <li>Cpun：第n个CPU的使用信息，sys包括softirq和irq</li>
  <li>Mem的状态：CPU处在系统模式下的时间百分比，包括irq和softirq的值；</li>
  <li>Swap的状态：CPU等待输入输出完成时间的百分比。</li>
  <li>进程对应的信息：进程ID，所属的用户，优先级，Nice值，这些信息都涉及到过;</li>
  <li>IRT：virtual memory usage 
    <ol>
      <li>进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 </li>
      <li>假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量 </li>
    </ol>
  </li>
  <li>RES：resident memory usage 常驻内存 
    <ol>
      <li>进程当前使用的内存大小，但不包括swap out </li>
      <li>包含其他进程的共享 </li>
      <li>如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反 </li>
      <li>关于库占用内存的情况，它只统计加载的库文件所占内存大小 </li>
    </ol>
  </li>
  <li>SHR：shared memory 
    <ol>
      <li>除了自身进程的共享内存，也包括其他进程的共享内存 </li>
      <li>虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 </li>
      <li>计算某个进程所占的物理内存大小公式：RES – SHR </li>
      <li>swap out后，它将会降下来 </li>
    </ol>
  </li>
  <li>DATA 
    <ol>
      <li>数据占用的内存。如果top没有显示，按f键可以显示出来。 </li>
      <li>真正的该程序要求的数据空间，是真正在运行中要使用的。</li>
    </ol>
  </li>
</ul>

<p>top命令下按f键可以看到详细说明</p>

<pre><code>* A: PID        = Process Id
* E: USER       = User Name
* H: PR         = Priority
* I: NI         = Nice value
* O: VIRT       = Virtual Image (kb)
* Q: RES        = Resident size (kb)
* T: SHR        = Shared Mem size (kb)
* W: S          = Process Status
* K: %CPU       = CPU usage
* N: %MEM       = Memory usage (RES)
* M: TIME+      = CPU Time, hundredths
b: PPID       = Parent Process Pid
c: RUSER      = Real user name
d: UID        = User Id
f: GROUP      = Group Name
g: TTY        = Controlling Tty
j: P          = Last used cpu (SMP)
p: SWAP       = Swapped size (kb)
l: TIME       = CPU Time
r: CODE       = Code size (kb)
s: DATA       = Data+Stack size (kb)
u: nFLT       = Page Fault count
v: nDRT       = Dirty Pages count
y: WCHAN      = Sleeping in Function
z: Flags      = Task Flags &lt;sched.h&gt;
* X: COMMAND    = Command name/line
</code></pre>

<p>top命令下要查看某个用户启动的进程：先输入u，然后输入用户名，再回车</p>

<h3 id="cpu-6">cpu的调优</h3>
<p>CPU的各种调优方法，具体可以参看<a href="http://coolshell.cn/articles/7490.html (性能调优攻略)">《性能调优攻略》</a>及其所列的参考资料，这里给出几种可能的调优方法
####改多线程/进程模型为使用epool</p>

<h4 id="cpucpu">多核心cpu绑定特定进程到指定cpu</h4>
<p>多核心的CPU系统有一个叫CPU亲和力的概念，能够将进指定程绑定到特定的CPU上。该方法能够优化性能的主要原因是由于CPU cache的优化。<br />
由于将进程绑定至特定的CPU上，避免了进程在各个CPU之间的调度切换，当进程在CPU间进行一次调度切换时，新CPU上的cache必须被flushed，如果进程在多个核心间来回切换，会导致多次cache的flushed，从而消耗更多CPU资源，这样导致每个的进程会花费更多的CPU时间。将进程绑定到特定的CPU上，能更好的局部化CPU的cache，同时提高cache命中率</p>

<ul>
  <li>
    <p>将mysql的进程绑定到指定的CPU</p>

    <ol>
      <li>如果程序还没有启动，使用taskset将其启动:
  taskset -cp 1,2,3 /etc/init.d/mysql start</li>
      <li>如果程序已经启动，并且不宜重启, 获取到其pid
  taskset -cp 1,2,3 pid</li>
    </ol>
  </li>
  <li>
    <p>将nginx的进程绑定到特定的CPU</p>

    <p>nginx 也可以使用上述方式，但nginx提供了更精确的控制。在conf/nginx.conf中，有如下一行：  </p>

    <pre><code>  worker_processes  1;     这是用来配置nginx启动几个工作进程的，默认为1。     nginx还支持一个名为worker_cpu_affinity的配置项，也就是说，nginx可以为每个工作进程绑定CPU。如下配置：  

  worker_processes  3;  
  worker_cpu_affinity 0010 0100 1000;     这里0010 0100 1000是掩码，分别代表第2、3、4颗cpu核心。
</code></pre>

    <p>重启nginx后，3个工作进程就可以各自用各自的CPU了。</p>
  </li>
  <li>
    <p>自己编写程序，绑定到指定的CPU</p>
    <ol>
      <li>如果自己写代码，要把进程绑定到CPU，该怎么做？可以用sched_setaffinity函数。在Linux上，这会触发一次系统调用。</li>
      <li>如果父进程设置了affinity，之后其创建的子进程是否会有同样的属性？我发现子进程确实继承了父进程的affinity属性。</li>
    </ol>
  </li>
</ul>

<h4 id="section-2">将单核心运行的程序，修改为多核心运行</h4>

<h2 id="section-3">内存</h2>
<p>内存完成的任务：</p>

<ol>
  <li>进程的执行空间</li>
  <li>进程内分配的空间</li>
  <li>缓存</li>
  <li>空闲</li>
</ol>

<h3 id="section-4">内存状态的查看和相关命令</h3>

<h3 id="malloc">malloc和延时分配</h3>

<h3 id="section-5">虚拟内存</h3>

<h2 id="io">磁盘IO</h2>

<h3 id="section-6">磁盘状态的查看和相关命令</h3>

<h3 id="cpu-7">磁盘，内存和CPU之间的影响</h3>

<h2 id="io-1">网卡IO</h2>
<p>###网卡的基本状态</p>

<h3 id="section-7">网卡的状态查看和相关工具</h3>

<h3 id="section-8">网卡的极限性能</h3>

<h1 id="section-9">常用的性能测试工具</h1>

<h2 id="http">HTTP：</h2>

<h3 id="ab">ab</h3>
<p>###siege
###curl-loader</p>

<h2 id="xmpp">XMPP</h2>
<p>###TSung</p>

<h1 id="section-10">如何分析定位分析系统的瓶颈</h1>
<ol>
  <li>
    <p>首先查看cpu，因为其最容易成为瓶颈</p>
  </li>
  <li>
    <p>查看网卡</p>
  </li>
  <li>
    <p>查看磁盘和内存</p>
  </li>
</ol>

<h1 id="demo">典型的瓶颈demo</h1>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><small>steal 值比较高的话，你需要向主机供应商申请扩容虚拟机。服务器上的另一个虚拟机可能拥有更大更多的 CPU 时间片，你可能需要申请升级以与之竞争。另外，高 steal 值可能意味着主机供应商在服务器上过量地出售虚拟机。如果升级了虚拟机，steal值还是不降的话，你应该寻找另一家服务供应商。低steal值意味着你的应用程序在目前的虚拟机上运作良好。因为你的虚拟机不会经常地为了CPU时间与其它虚拟机激烈竞争，你的虚拟机会更快地响应。这一点也暗示了，你的主机供应商没有过量地出售虚拟服务，绝对是一件好事情。</small><a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><small>你可能发现，如果tick是linux操作系统度量时间的基本单位，那我们常用的timeval变量中的tv_usec这个变量准确么？因为如果tick=250，则最小的时间间隔为4ms，实际上这是两个概念，tick时操作系统进行系统调度等的时间间隔，而我们一般获取操作系统的时间，是从cmos电路中获取的时间，一般是从某一历史时刻开始到现在的时间，也就是为了取得我们操作系统上显示的日期。这个就是所谓的“实时时钟”，它的精确度是微秒。另外，系统还有一个与时间有关的时钟：实时时钟（RTC），这是一个硬件时钟，用来持久存放系统时间，系统关闭后靠主板上的微型电池保持计时。系统启动时，内核通过读取RTC来初始化Wall Time,并存放在xtime变量中，这是RTC最主要的作用。一般是在BIOS中，这也是我们的机器在关机重启后，仍然能够获取正确的取得时间的原因</small><a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><small>从网上找的含义是这个，但是实际上，我查看的意义为该机器上次启动的时间戳。</small><a href="#fnref:3" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
	</entry>
	
	<entry>
		<title>amazon 2012-10-22 事故分析总结</title>
		<link href="http://iguowei.net/posts/amazon-service-event.html" />
		<updated>2012-11-22T00:00:00+08:00</updated>
		<id>http://iguowei.net/posts/amazon-service-event.html</id>
		<content type="html"><![CDATA[<p>amazon在2012年10月22在美国东海岸发生了服务故障，他们的团队事后进行了分析和总结，本文是其英文版的翻译，<a href="https://aws.amazon.com/message/680342/">原文点击这里</a></p>

<h1 id="section">事故描述</h1>

<ol>
  <li>星期一10:00AM PDT, 东海岸5个区域中的一个Zone发生少量的Elastic Block Store (EBS)服务拒绝，具体表现为无法进行IO请求,原因为agent在某个异常状态下会发生内存泄漏，而这个内存泄漏是和请求相关的；</li>
  <li>服务拒绝的EBS机器到达了某个临界值，开始发生雪崩，很快更多的机器无法处理用户请求，导致更多的机器无法进行IO请求；</li>
  <li>11:00AM左右，这个Zone中的大部分EBS volume无法使用；</li>
  <li>11:15AM左右，为了恢复服务，团队决定减少故障转移率，采取限制流量的措施，防止更多机器雪崩；</li>
  <li>11:35AM，系统开始自动恢复部分EBS 存储volume；</li>
  <li>1:40PM，60%受影响的volume被恢复，团队继续查找原因，并继续恢复余下有问题的volume。由于故障转移和恢复的量太大，导致团队很难真正定位问题；</li>
  <li>3:10PM，团队定位出真正的问题，并通过释放agent多占的内存来恢复剩下大部分未被恢复的volume；
8。4:15PM，所有受影响的存储volume均被恢复至正常状态</li>
</ol>

<h1 id="section-1">原因</h1>

<ol>
  <li>EBS 服务拒绝原因：
    <ul>
      <li>EBS 存储服务器上收集数据的agent有一个潜在的bug, 个人理解agent的作用类似于Mola的agent，个人猜测该agent既可以读数据，也可以写数据。agent设计为对时间不敏感和对数据的延时和缺失有容错性。</li>
      <li>上周，其中一台存储机器(chunk)硬件故障并被替换，同时内部DNS(可能用做寻地址，这里估计agent查找后端的server是通过域名，而不是ip来查找)进行更新。</li>
      <li>因为没有注意到，内部DNS并没有完成更新记录成功，导致少部分机器继续连接已经下架的机器，而不是更新后的好机器，因为架构设计允许数据缺失，这个问题并没有立即触发报警.</li>
      <li>但这种重试，触发了reporting agent(和刚刚的agent是一个？)上一个隐藏的内存泄漏的bug。而且这个泄漏是和重试次数相关的，这样就导致agent内存持续的被消耗。</li>
      <li>amazon有监控每个EBS server的总的内存消耗，但是这种消耗，监控系统并没有报警，EBS 由于需要处理用户的数据，其使用的内存差异很大，导致无法设置关于内存使用量的报警策略。</li>
      <li>周一早上，由于内存泄漏已经非常高了，导致无法正常的处理用户的正常请求。</li>
    </ul>
  </li>
  <li>雪崩的原因
    <ul>
      <li>所有云服务的冗余设计，将请求从故障机器转移到服务OK的机器上。由于同时内存泄漏的机器太多，导致没有足够多服务状态OK的机器能够处理转移请求，同时由于内存泄漏的机器更多，导致更多的agent内存泄漏，就导致更多的机器无法服务。</li>
    </ul>
  </li>
</ol>

<h1 id="section-2">后期的防备措施</h1>

<ol>
  <li>针对这种内存泄漏，在所有EBS服务器上进行监控；</li>
  <li>下周开始，对所有的EBS服务器(包括不同地区)部署新的fix版本；</li>
  <li>修改系统监控，针对EBS服务器上<strong>每个进程</strong>进行内存消耗的监控；</li>
  <li>后续部署资源限制，阻止低优先级别的进程过多的使用机器上的资源；</li>
  <li>更新内部DNS配置，确保每次DNS的更新都是可靠的到达每台机器；更重要的是，针对这种未更新成功的情况，监控系统能够做出及时的报警；</li>
</ol>

<p>上面的这些措施，均能及早的定位引发这次事故的原因。另外，还需要评估如何修改EBS故障转移的逻辑，以避免类似这次快速的大范围的雪崩情况</p>

<h1 id="section-3">造成的影响</h1>

<h2 id="ec2ebs-apis-">对EC2和EBS APIs 的影响</h2>

<ul>
  <li>描述: 这个事故只影响了一个Zone的EBS volume服务，如果用户在其它的Zone上有足够的空间，理论上其所受的影响不大。amazon投入了大量的精力来避免service APIs受到单个Zone出事故而造成的影响。但实际上仍然有用户抱怨在这次事故中，无法进行IO操作，而此时amazon的监控系统显示EBS APIs服务正常。原因为Api的限流，并没有均匀的分布到所有的用户，造成部分用户被Api限流过于限制导致无法操作资源</li>
  <li>amazon使用限流来保证内部或者外部，恶意或者非恶意的大量访问，参见<a href="http://coolshell.cn/articles/5701.html">SteveY的吐槽</a>,<a href="http://news.ycombinator.com/item?id=3102800">英文版</a>，amazon的平台在设计之初，就非常关注配额和限流。对于单个应用，在获取某个正确结果前的多次重试，平台是可以处理的。但是在这次事故中，所有的application一起发生故障，导致对平台产生了大量的负载，amazon有一个基础的限制浏览的方案。为了保证恢复过程中其他正常机器服务的稳定和不正常机器的恢复，团队制定了非常激进的限流措施，后面证实这个措施过于激进了。</li>
  <li>原因: 12:06PM PDT 团队执行了这个激进的限流措施，同时在监控着整体的流量和其他活动，由于监控显示正常，并没有意识到用户已经受到了显著的影响。后来意识到，少部分用户在这个限流策略下，被极高比例的限制Api调用，这些Api调用维持了大量的用户在调用他们的EC2实例和EBS资源，由于这些用户被限制的非常厉害，导致他们在事故中调用APIS服务很难成功，同时影响到他们通过AWS的管理平台来管EC2服务和EBS资源，直到 2:33PM PDT，团队才显著的减少了限流的程度。</li>
  <li>后续的改进: 1. 故障处理中减少使用这种激进的处理策略，使用其它即能够恢复服务，又减少用户感知的限流策略；2. 操作dashbord上增加精细到用户级别的限流监控，而不仅仅是整体的限流监控，以减少这种情况再次发生，同时做出最准确的判断。</li>
  <li>限流是维持服务健康非常重要的工具，同时由于用户有经常更改限流强度的需求（amazon提供按需服务），amazon在不影响用户使用服务的前提下部署使用。从这次事故中，限流措施对许多用户造成的影响远超过团队的最初的意识。这次限流中，没有明显影响到跨多个Zone的程序，但影响到了许多单Zone的用户，导致他们在几个无法恢复到健康状态，甚至是正常工作的down。后面就是赔偿balala的。。。</li>
</ul>

<h2 id="rdsamazon-relational-database-service">对RDS(Amazon Relational Database Service)的影响</h2>

<ul>
  <li>描述：因为RDS使用EBS来存储database和log，所以部分在受影响区域的RDS database在这次事故中也悲剧了。当然，使用其它Zone的RDS instance是不受影响的。</li>
  <li>amazon的RDS有两种使用模式：Single Availability Zone (Single-AZ)单区域(唯一的一个single DataBase instance in one Zone)和Multi Availability Zone (Multi-AZ)多区域(两个database instance in two different Zone)，类似于mysql的主从模式，其中一个为主一个为从，正常情况下，主database hold住所有的请求，并复制到从上，在主挂掉时，从完成完整性check后，迅速的变为主。</li>
  <li>Single-AZ的database实例在受影响的Zone中被直接影响了。在事故中，如果database实例使用的一个EBS volume有问题，则会被影响到，具体表现为IO请求异常(如上所描述)，Single-AZ的恢复，依赖于其底层使用的EBS volume的恢复。1:30PM PDT, 很多受影响的Single-AZ RDS instance被恢复，3:30PM PDT, 主要的受影响的database instance 被恢复，6:35PM PDT, 几乎所有的Single-AZ RDS instances 恢复。</li>
  <li>大部分的Multi-AZ在完成一致性check后，能够正常的切换到健康的Zone的从上，但是由于存在两个完全不同的bug（吐槽一下,bug真心多啊，哈哈），低于10%的Mulit-AZ database instance没有自动的完成故障转移。
    <ol>
      <li>部分instance没有正确转移是因为碰到了一个不寻常的IO操作，导致转移逻辑没有正常处理，这些instance需要操作动作，并且存储的时间是11:30AM（个人估计是故障转移时需要写IO操作，而IO操作刚好是在11:30AM这个有问题的时候，导致异常，没太看明白这个bug）</li>
      <li>第二个bug的触发条件:a.master database instance 和从的连接断了一个很短的时间；b. 此时master的database instance写volume失败，两者几乎同时进行；c. 从master和slave连接丢失到master database写volume失败这段时间内，master还在处理业务，而没有将其转移到其从上；在master的IO请求无法处理时，此时系统因为slave的数据是过时的数据（integrity check 失败）而被block住了。后续的修改：在master的Zone出现问题开始时，立马进行故障转移；由于问题涉及比较广,估计整个要到12月才能修复并完全上线。database instance在EBS volume恢复后就恢复了。在这两个bug修复后，预计Multi-AZ的问题就会被修复，这两个问题是团队后面最高的优先级,balala&#8230;</li>
    </ol>
  </li>
  <li>如果一个application是Multi-AZ，同时在一个Zone不可用后，仍然有足够的资源来进行后续操作的话，那么这个程序应该是可用的。后面又是赔偿等一些balala的&#8230;	</li>
</ul>

<h2 id="elbamazon-elastic-load-balancing">对ELB(Amazon Elastic Load Balancing)的影响</h2>

<ul>
  <li>每个ELB load balancer 使用一个或者多个load balancer 实例做用户EC2实例的路由。ELB使用EBS来存储配置和监控信息。当ELB实例使用的EBSvolume被hung住的时候，部分ELB服务就变得不可用，此时ELB服务开始启动恢复流程来恢复或者替代有问题的load balancer实例。
用户的application中使用的ELB服务可以是位于1个或者多个Zone的ELB服务</li>
  <li>如果用户的ELB绑定的application运行在一个Zone中，ELB的load balancer实例和application被设定运行在同一个区域。在这次事故中，部分Single-AZ load balancer的服务由于部分的load balancer实例无法从EBS中进行IO操作而发生服务故障。这些影响在ELB system能够从受影响的Zone中获取到可用的EBS volume后迅速恢复了。1:10PM PDT, 主要受影响的单Zone的load balancer都被恢复；3:30PM PDT，大部分的的load balancers被恢复；最后一批load balancer被恢复很慢，是由于ELB的恢复策略导致的问题。ELB是用弹性IP池(Elastic IP addresses (EIPs))来可靠的将流量路由到EC2的实例上。EIPs被新的load balancer实例和恢复的load balancer消耗，同时原有的ELB的EIPs未被释放掉，导致所有的EIPs被全部消耗完毕。团队后来手动修复了最后一批失败的load balancer的实例，修复了EIPs的短缺，9:50PM PDT 完成全部修复</li>
  <li>后续改进：
    <ol>
      <li>减少ELB的恢复时间；</li>
      <li>保证每个Zone在恢复的时候有足够的EIPs；</li>
      <li>较少ELB和EBS间的耦合，允许在一个Zone内即使EBS有问题，ELB仍然可以恢复；</li>
      <li>后续添加若干ELB的恢复流程的改进来改善类似事故中ELB的恢复时间;</li>
    </ol>
  </li>
  <li>如果用户的ELB绑定的application运行在多个Zone中，ELB会为application运行的每个区域设置一个load balancer实例，ELB会自动将服务质量降低区域的流量切走，以保证服务的快速恢复。在这次事故中，多Zone的ELB服务，会明显感受到访问错误率的升高。11:49AM PDT, 大部分的ELB service 从受影响的区域切走到那些未受影响的区域。不幸的是，流量切换函数中的一个bug，导致少部分受影响的load balancer没有被正确的map，从而导致流量没有被正常的切走。这些load balancer持续的发送用户的请求到受影响的Zone。直到12:45PM这个问题被正确的定位。</li>
  <li>改进:
    <ol>
      <li>修复了这个逻辑bug，保证以后不会再出现；</li>
      <li>采取若干措施提高流量切换过程的灵敏度，使得将来流量能更快的从受影响的区域切走;</li>
      <li>将流量切换函数保留给用户，使得他们可以自己控制将流量切换到可用的区域;</li>
      <li>协助用户使用我们的流量迁移策略，是的他们可以自己处理这种一个Zone失败的情况(按照平台的设计思想，这个应该是对用户透明的，个人觉得是在问题发生的时候，amazon没有足够的人手来处理这个问题，而这个对用户的影响很大，所以很多用户要求有自己处理流量转移的权限)；</li>
    </ol>
  </li>
</ul>

<h1 id="aws">AWS目前能够完成的功能</h1>
<ol>
  <li>优点：
    <ul>
      <li>配额和节流，amazon的配额和节流是事故从雪崩的状态慢慢恢复的最重要手段；</li>
      <li>无处不在的监控，从上面的描述来看，他们的监控已经做到整体上的各个角度监控，后续监控可能会细粒度到用户这一层；</li>
      <li>自动化，自动化故障迁移，自动化的流量切换，听说amazon可能是IT公司中自动化工具最多的公司。。。</li>
    </ul>
  </li>
  <li>缺点：
    <ul>
      <li>bug有点多啊，这个事故中共有四个bug，当然是不同的产品线，也是非常难以触发的bug。可能云的产品测试，需要将异常情况作为常态来测试，同时要真正的模拟异常的场景，如果是手动测试，成本很难接受，尤其是不停的迭代；如果是自动化测试，对技术要求非常高。成本也不低；</li>
      <li>产品线的耦合比较高。。。这个不知道算不算缺点，按道理来说应该是尽可能的复用已有的产品，但是复用别人的产品，应该做好依赖的产品不可靠的最坏准备。</li>
    </ul>
  </li>
</ol>

<h1 id="bcs">之前BCS已经完成的功能</h1>
<ol>
  <li>优点:
    <ul>
      <li>BCS对内和对外做了两套系统，对内的是不限制额度和流量的。对外的是精确限制额度和流量的，既可以整体限制，也可以精确到bucket级别，还有针对特殊bucket的特殊策略(内部版)，这个地方其实可以从一个更高更统一的角度进一步改进。</li>
      <li>相对来说BCS的监控可能做的可能要简单些。BCS的监控有：基础项的监控(不知道有没有精确到进程级别的监控，如内存等等)，错误日志的监控，状态服务码的监控，bucket基本的监控(但只有top*** bucket的监控)，上层的语义监控不知道现在做了没。其实如果再次设计一个BCS，监控的优先级可以提高，投入多一些精力，界面做的更加人性化。</li>
      <li>BCS的内部模块通信都有重试机制，但是这个离真正的自动化还是有较远的距离。自动化运维，故障转移自动化，貌似最近在上多Zone，多Zone间的通讯，同步，流量自动迁移。。。技术挑战还是非常高的。</li>
    </ul>
  </li>
  <li>缺点：
    <ul>
      <li>bug也很多，惭愧一下，基本上面发生的bug，差不多都会经历的吧，比如：BCS中一个模块在异常连接失败后的内存泄漏，我自己漏测过。。。 </li>
      <li>BCS也和其他产品存在耦合，比如：BAE，但是如果BCS全部down掉，BAE只有无法发布新应用的影响，而不会导致BAE服务停止。当然，如果应用有写BCS的请求，仍然会有影响。BCS也有部分模块运行在BAE上，但不是核心功能。其他新的业务，不清楚他们的耦合怎么样。</li>
    </ul>
  </li>
</ol>

<h1 id="section-4">感想</h1>
<ul>
  <li>从之前做BCS到后面的PCS，到学习这个事故，发现云计算机器数目的增加，不仅仅只是原来技术方案的扩倍，它会带来很多新问题需要解决，会带来更多新的技术挑战。在少量机器下不明显的问题，在大量机器下，可能要花很多经历去解决。一个简单的类比例子是：一个普通工程师，通过信任关系+ssh+rsync 基本可以管理10台服务器；但是如果要管理100台服务器，这个方法可能不灵验了，只有让一个OP工程师来搞定了；如果要管理1000台服务器，可能普通OP工程师也搞不定了，10个普通OP工程师也搞不定，想象一下不同的产品线，在不同数量的机器上上线，工程师之间的沟通成本，你可能需要一个运维团队使用不同的分工来搞定。如果是10000台，100000台机器，按不同的组来分工管理，也可以搞得定，但是成本一定不低，这个时候就需要机器自动化的管理方案了，很有技术含量。</li>
  <li>之前做BCS，我们没有发生过一次雪崩的情况，不是我们比较牛B，而是：1. 机器的数目没达到，到不了雪崩的临界值；2. 自动化运维做的比较差，或者说没有自动化的迁移，所以无法雪崩；哪天如果真雪崩了，说明了BCS已经做的非常的前沿和牛B了。</li>
  <li>将异常情况当作常态来测试，对做云相关的非常重要，但是真的很难做好。</li>
  <li>做云还是很苦B的，对岸amazon的工程师，处理这个event，不是从白天10:00，处理到凌晨12:45PM么?</li>
</ul>

]]></content>
	</entry>
	
	<entry>
		<title>lvs 测试</title>
		<link href="http://iguowei.net/posts/lvs-test.html" />
		<updated>2012-11-21T00:00:00+08:00</updated>
		<id>http://iguowei.net/posts/lvs-test.html</id>
		<content type="html"><![CDATA[<p>敬请期待&#8230;</p>
]]></content>
	</entry>
	
	<entry>
		<title>pyinotify使用中的陷阱</title>
		<link href="http://iguowei.net/posts/pyinotify.html" />
		<updated>2012-11-16T00:00:00+08:00</updated>
		<id>http://iguowei.net/posts/pyinotify.html</id>
		<content type="html"><![CDATA[<p>在做米聊线上监控报警工具的时候，需要将每次的监控数据进行记录，这里采用了以下流程。</p>

<p><img src="/assets/pic/2012-11-16-miliao.png" alt="米聊在线服务预警图" /></p>

<p>探测程序会定期将自己的探测结果以xml文件的形式写入到特定的目录中，监控程序会监控该目录并到新写入的数据，并插入数据库。报警程序会定期扫描数据库中的数据，结合报警策略，决定是否进行报警。</p>

<pre><code>问：为啥探测程序会是写入特定的目录中，再有监控程序写入数据库，而不是直接写数据库?

答：1. 保证探测程序的简单性，不做过多的事件。

2. 解耦合，监控程序类似于一个agent，可以支持更多不同语义的监控。

3. 监控＋报警这样更容易做成一个服务


问：为啥监控程序会将监控数据写入数据库，而不是直接决定是否报警

答：1. 报警策略可能需要结合监控的多个状态来报警。

2. 更重要的是，满足可以网页可以浏览在过去一段时间内的监控状态
</code></pre>

<p>如何获取一个指定的目录下，是否有新的数据写入？
两种方法：</p>

<ol>
  <li>启动一个线程，定期扫描该文件夹，如果某个文件不存在之前的文件hash表中，则为新增的数据。或者每次写入的文件名相同，此时，比较本次的时间和上次的时间是否相同。</li>
  <li>使用inotify，在文件夹下有自己感兴趣的event发生时，则调用回调函数，写入数据库中</li>
</ol>

<p>方法二相对于方法一，减少了定期的轮询开销，减少了前后两个状态的对比，处理方式相对更加优雅。</p>

<p>监控程序使用python编写，所以使用pyinotify来实现inotify的监控。inotify 既可以监视文件，也可以监视目录，可以监视的文件系统事件包括：</p>

<table>
	<tr>
		<td>Event Name</td><td>Is an Event</td><td> Description</td>
	</tr>
	<tr>
		<td>IN_ACCESS</td><td>YES</td><td>file was accessed</td>
	</tr>
	<tr>
		<td>IN_ATTRIB</td><td>YES</td><td>metadata changed</td>
	</tr>
	<tr>
		<td>IN_CLOSE_WRITE</td><td>YES</td><td>writtable file was closed</td>
	</tr>
	<tr>
		<td>IN_CREATE</td><td>YES</td><td>file/dir was created in watched directory</td>
	</tr>
	<tr>
		<td>IN_DELETE</td><td>YES</td><td>file/dir was deleted in watched directory</td>
	</tr>
	<tr>
		<td>IN_MODIFY</td><td>YES</td><td>file was modified</td>
	</tr>
	<tr>
		<td>IN_OPEN</td><td>YES</td><td>file was opened</td>
	</tr>	
</table>

<p>通过pyinotify来实现对文件系统的监控非常简单，如下是一个demo，只需要重写对应的回调函数既可。</p>

<pre><code>#!/usr/bin/env python
# encoding:utf-8
 
import os
from  pyinotify import  WatchManager, Notifier, \
ProcessEvent,IN_DELETE, IN_CREATE,IN_MODIFY
 
class EventHandler(ProcessEvent):
    """事件处理"""
    def process_IN_CREATE(self, event):
        print   "Create file: %s "  %   os.path.join(event.path,event.name)
 
    def process_IN_DELETE(self, event):
        print   "Delete file: %s "  %   os.path.join(event.path,event.name)
 
    def process_IN_MODIFY(self, event):
        print   "Modify file: %s "  %   os.path.join(event.path,event.name)
 
def FSMonitor(path='.'):
    wm = WatchManager() 
    mask = IN_DELETE | IN_CREATE |IN_MODIFY
    notifier = Notifier(wm, EventHandler())
    wm.add_watch(path, mask,rec=True)
    print 'now starting monitor %s'%(path)
    while True:
        try:
            notifier.process_events()
            if notifier.check_events():
                notifier.read_events()
        except KeyboardInterrupt:
            notifier.stop()
            break
 
if __name__ == "__main__":
    FSMonitor()
</code></pre>

<p>放在本项目中，则被hook的函数为IN_CREATE，因为每次探测程序都会写数据到新的文件，然后定期删除监控的数据。但是一个诡异的问题出现了：在IN_CREATE事件发生时，调用程序读取新的数据，读取函数返回错误：
	xml.parsers.expat.ExpatError: no element found: line 1, column 0</p>

<p>google 该错误信息，很多都说是open了file后忘记了关闭，但是我在这里已经做了close的动作。而且这个问题的出现，是偶尔发生的。</p>

<p>思考后，发现是读取element没有读取到，是不是和文件的content有关，没办法，只能抓日志，并查看content的日志是否合法了，有了这个思路后，下一次一发生这个文件，就找到原因了。content的长度为0，难怪会打印这个错误。</p>

<p>于是疑问来了，为啥content的内容会为0？打开文件时，明明长度是存在的。当然，sleep 1s，基本可以规避这个问题。但是明显没有完全解决这个问题。</p>

<p>后面回去的路上，仔细考虑这个问题，并将demo代码中的事件都监控起来，终于找到问题的根源了。</p>

<p>创建文件的方法为：</p>

<pre><code>f = open(filename, 'w')
...
dom.writexml(f, addindent='  ', newl='\n', encoding='utf-8')
f.close()
</code></pre>

<p>在这里，实际发生了三个事件，分别是IN_CREATE, IN_MODIFY, IN_CLOSE_WRITE, 分别对应于这三步，虽然我们平时说的是创建一个文件，但在inotify中，创建文件和我们平时指的还是有较大差别。</p>

<p>修复方法自然也出来了，将监控的事件修改为IN_CLOSE_WRITE，问题解决。sleep 只是一个不治本的方法。</p>
]]></content>
	</entry>
	
	<entry>
		<title>你好，世界</title>
		<link href="http://iguowei.net/posts/hello-world.html" />
		<updated>2012-11-07T00:00:00+08:00</updated>
		<id>http://iguowei.net/posts/hello-world.html</id>
		<content type="html"><![CDATA[<h2>你好，世界</h2>
<p>我在github上的第一篇文章，也是在github上搭建自己的blog成功的一天</p>
<p>07 Nov 2012</p>
]]></content>
	</entry>
	
</feed>